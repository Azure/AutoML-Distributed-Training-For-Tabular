{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "Copyright (c) Microsoft Corporation. All rights reserved.\n",
    "\n",
    "Licensed under the MIT License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "![Impressions](https://PixelServer20190423114238.azurewebsites.net/api/impressions/MachineLearningNotebooks/how-to-use-azureml/automated-machine-learning/forecasting-beer-remote/auto-ml-forecasting-beer-remote.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "# Automated Machine Learning\n",
    "**Distributed TCN Forecasting**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates demand forecasting for UCI Electricity Dataset using AutoML where the objective is to predict electricity consumption 24 hours ahead for each of the stations. The original dataset lists electricity consumption every 15 minutes. We aggregated the original data to an hourly frequency.\n",
    "\n",
    "AutoML highlights here include using TCNForecaster (a deep learning model for forecasting) in a distributed fashion, Remote Inferencing, and working with the `forecast` function. Please also look at the additional forecasting notebooks, which document lagging, rolling windows, forecast quantiles, other ways to use the forecast function, and forecaster deployment.\n",
    "\n",
    "**Contents**:\n",
    "\n",
    "1. Creating an Experiment in an existing Workspace\n",
    "2. Configuration and remote run of AutoML for a time-series model exploring DNNs\n",
    "4. Evaluating the fitted model using a rolling evaluation\n",
    "5. Deploying the model to a web service"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "## Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import logging\n",
    "\n",
    "import azureml.core\n",
    "from azureml.core import Workspace, Experiment, Dataset\n",
    "from azureml.train.automl import AutoMLConfig\n",
    "from azureml.exceptions import UserErrorException\n",
    "from azureml.automl.core.forecasting_parameters import ForecastingParameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is compatible with Azure ML SDK version 1.49.0 or later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"You are currently using version\", azureml.core.VERSION, \"of the Azure ML SDK\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "Make sure you already have a <b>Workspace</b> created. If not, please refer [this link](https://learn.microsoft.com/en-us/azure/machine-learning/quickstart-create-resources#create-the-workspace) to create a workspace. To run AutoML, you also need to create an <b>Experiment</b>. An Experiment corresponds to a prediction problem you are trying to solve, while a Run corresponds to a specific approach to the problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "ws = Workspace.from_config()\n",
    "\n",
    "experiment_name = \"distributed-tcn\"\n",
    "experiment = Experiment(ws, experiment_name)\n",
    "\n",
    "datastore = ws.get_default_datastore()\n",
    "\n",
    "output = {}\n",
    "output[\"Subscription ID\"] = ws.subscription_id\n",
    "output[\"Workspace\"] = ws.name\n",
    "output[\"Resource Group\"] = ws.resource_group\n",
    "output[\"Location\"] = ws.location\n",
    "output[\"Run History Name\"] = experiment_name\n",
    "output[\"SDK Version\"] = azureml.core.VERSION\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "outputDf = pd.DataFrame(data=output, index=[\"\"])\n",
    "outputDf.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "### Using AmlCompute\n",
    "You will need to create a [compute target](https://docs.microsoft.com/azure/machine-learning/service/concept-azure-machine-learning-architecture#compute-target) for your AutoML run. In this tutorial, you use `AmlCompute` as your training compute resource.\n",
    "\n",
    "> Note that if you have an AzureML Data Scientist role, you will not have permission to create compute resources. Talk to your workspace or IT admin to create the compute targets described in this section, if they do not already exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "# Choose a name for your CPU cluster\n",
    "cpu_cluster_name = \"distributed-tcn-cluster\"\n",
    "\n",
    "# Verify that cluster does not exist already\n",
    "try:\n",
    "    compute_target = ComputeTarget(workspace=ws, name=cpu_cluster_name)\n",
    "    print(\"Found existing cluster, use it.\")\n",
    "except ComputeTargetException:\n",
    "    compute_config = AmlCompute.provisioning_configuration(\n",
    "        vm_size=\"Standard_NC6s_v3\", max_nodes=6\n",
    "    )\n",
    "    compute_target = ComputeTarget.create(ws, cpu_cluster_name, compute_config)\n",
    "\n",
    "compute_target.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "We will be using UCI Electricity dataset. Original data can be found [here](https://archive.ics.uci.edu/ml/datasets/ElectricityLoadDiagrams20112014). The data has been aggregated to the hourly frequency and a subset of it is taken. Below is a summary of the sets we will be using:\n",
    "\n",
    "| Dataset | Start DateTime | End DateTime | No. of Timeseries |\n",
    "| - | - | - | - |\n",
    "| Train | 2012-01-01 00:00:00 | 2013-10-19 15:00:00 | 15 |\n",
    "| Valid | 2013-10-19 16:00:00 | 2014-05-26 19:00:00 | 15 |\n",
    "| Test | 2014-05-26 20:00:00 | 2014-12-31 23:00:00 | 15 |\n",
    "\n",
    "This step expects that the dataset has already been partitioned based on ``time_series_id_column_names`` (column names used to uniquely identify the time series in data that has multiple rows with the same timestamp), which means you should have:\n",
    "- partitioned train data\n",
    "- partitioned validation data\n",
    "- test data\n",
    "\n",
    "**If this is not the case, please run [this notebook](./data-partition.ipynb) to prepare the data only if the total size of data is in GBs. For smaller datasets, like the ones we are using, this step will handle the partitioning.**\n",
    "\n",
    "Once we have the prepared data registered in the worksapce, we can retrieve them using ``get_by_name`` method from ``Dataset`` class.\n",
    "\n",
    "Following variables are specific to the dataset and must be updated accordingly:\n",
    "\n",
    "| Variables | Description |\n",
    "| - | - |\n",
    "| **dataset_name** | Name for the dataset, used while data registration and writing to datastore. |\n",
    "| **time_column_name** | Name of your time column. |\n",
    "| **time_series_id_column_names** | The column names used to uniquely identify the time series in data that has multiple rows with the same timestamp. These columns will be used to partition the data. |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"electricity\"\n",
    "partitioned_dataset_name = f\"{dataset_name}_partitioned\"\n",
    "time_column_name = \"datetime\"\n",
    "time_series_id_column_names = [\"station\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "from helper import register_dataset\n",
    "\n",
    "\n",
    "try:\n",
    "    train_dataset = Dataset.get_by_name(\n",
    "        workspace=ws, name=f\"{partitioned_dataset_name}_train\"\n",
    "    )\n",
    "except UserErrorException:\n",
    "    train_dataset = register_dataset(\n",
    "        src_dir=\"./data/train\",\n",
    "        target=f\"{dataset_name}/train\",\n",
    "        name=f\"{partitioned_dataset_name}_train\",\n",
    "        partition_column_names=time_series_id_column_names,\n",
    "    )\n",
    "\n",
    "try:\n",
    "    valid_dataset = Dataset.get_by_name(\n",
    "        workspace=ws, name=f\"{partitioned_dataset_name}_valid\"\n",
    "    )\n",
    "except UserErrorException:\n",
    "    valid_dataset = register_dataset(\n",
    "        src_dir=\"./data/valid\",\n",
    "        target=f\"{dataset_name}/valid\",\n",
    "        name=f\"{partitioned_dataset_name}_valid\",\n",
    "        partition_column_names=time_series_id_column_names,\n",
    "    )\n",
    "\n",
    "try:\n",
    "    test_dataset = Dataset.get_by_name(workspace=ws, name=f\"{dataset_name}_test\")\n",
    "except UserErrorException:\n",
    "    test_dataset = register_dataset(\n",
    "        src_dir=\"./data/test\",\n",
    "        target=f\"{dataset_name}/test\",\n",
    "        name=f\"{dataset_name}_test\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to create ``ForecastingParameters`` and ``AutoMLConfig`` objects.\n",
    "\n",
    "#### ``ForecastingParameters`` arguments\n",
    "To define forecasting parameters for your experiment training, you can leverage the ``ForecastingParameters`` class. The table below details the forecasting parameter we will be passing into our experiment.\n",
    "\n",
    "|Property|Description|\n",
    "|-|-|\n",
    "|**time_column_name**|The name of your time column.|\n",
    "|**forecast_horizon**|The forecast horizon is how many periods forward you would like to forecast. This integer horizon is in units of the timeseries frequency (e.g. daily, weekly).|\n",
    "|**time_series_id_column_names**|The column names used to uniquely identify the time series in data that has multiple rows with the same timestamp. If the time series identifiers are not defined, the data set is assumed to be one time series.|\n",
    "|**freq**|Forecast frequency. This optional parameter represents the period with which the forecast is desired, for example, daily, weekly, yearly, etc. Use this parameter for the correction of time series containing irregular data points or for padding of short time series. The frequency needs to be a pandas offset alias. Please refer to [pandas documentation](https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#dateoffset-objects) for more information.\n",
    "\n",
    "#### ``AutoMLConfig`` arguments\n",
    "Instantiate an AutoMLConfig object. This defines the settings and data used to run the experiment.\n",
    "\n",
    "| Property                           | Description|\n",
    "| :---------------                   | :------------------- |\n",
    "| **task**                           | forecasting |\n",
    "| **primary_metric**                 | This is the metric that you want to optimize.<br> Forecasting supports the following primary metrics <br><i>spearman_correlation</i><br><i>normalized_root_mean_squared_error</i><br><i>r2_score</i><br><i>normalized_mean_absolute_error</i> |\n",
    "| **training_data**                  | Input dataset, containing both features and label column. |\n",
    "| **validation_data**                | Validation dataset, containing both features and label column. |\n",
    "| **test_data**                      | Test dataset, containing both features and label column. This will trigger test run at the end of the training and we can use it to view the test metrics. |\n",
    "| **label_column_name**              | The name of the label column. |\n",
    "| **compute_target**                 | The remote compute for training. |\n",
    "| **experiment_timeout_hours**       | Maximum amount of time in hours that each experiment can take before it terminates. This is optional but provides customers with greater control on exit criteria. |\n",
    "| **enable_early_stopping**          | Flag to enable early termination if the primary metric is no longer improving. |\n",
    "| **verbosity**                      | The verbosity level for writing to the log file. The default is INFO or 20. Acceptable values are defined in the Python [logging library](https://docs.python.org/3/library/logging.html). **We encourage setting it to ERROR or 40 for larger datasets to avoid generating high volume of logs which could lead to experiment failure.** |\n",
    "| **iterations**                     | Number of models to train. This is optional but provides customers with greater control on exit criteria. **We recommend to use more the 50 completed HyperDrive runs to find the best model**. We are using a small number of iterations to reduce the runtime and this comes, potentially, at the expense of accuracy.|\n",
    "| **iteration_timeout_minutes**      | Maximum amount of time in minutes that the model can train. This is optional but provides customers with greater control on exit criteria. |\n",
    "| **max_concurrent_iterations**      | Number of models to train in parallel. |\n",
    "| **enable_dnn**                     | Enable Forecasting DNNs. |\n",
    "| **allowed_models**                 | A list of model names to search for an experiment. If not specified, then all models supported for the task are used minus any specified in ``blocked_models`` or deprecated TensorFlow models. The supported models for each task type are described in the ``azureml.train.automl.constants.SupportedModels`` class. |\n",
    "| **use_distributed**                | This enables distributed training and must be set to True. |\n",
    "| **forecasting_parameters**         | The ``ForecastingParameters`` object defined above. |\n",
    "| **max_nodes**                      | Maximum number of nodes to use in training. We encourage this value to be a multiple of max_concurrent_iterations. The multiple indicates the number of nodes that will be used by each concurrent iteration. Minimum acceptable value to kick off distributed training is 2. |\n",
    "\n",
    "<br/>\n",
    "\n",
    "> **Note**: Cross Validation is not supported by Distributed TCN right now. And the data needs to be multi-timeseries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "target_column_name = \"target\"\n",
    "time_column_name = \"datetime\"\n",
    "freq = \"H\"\n",
    "forecast_horizon = 24\n",
    "\n",
    "forecasting_parameters = ForecastingParameters(\n",
    "    time_column_name=time_column_name,\n",
    "    forecast_horizon=forecast_horizon,\n",
    "    time_series_id_column_names=time_series_id_column_names,\n",
    "    freq=freq,\n",
    ")\n",
    "\n",
    "# To only allow the TCNForecaster we set the allowed_models parameter to reflect this.\n",
    "automl_config = AutoMLConfig(\n",
    "    task=\"forecasting\",\n",
    "    primary_metric=\"normalized_root_mean_squared_error\",\n",
    "    training_data=train_dataset,  # The data has to be partitioned.\n",
    "    validation_data=valid_dataset,  # The data has to be partitioned.\n",
    "    test_data=test_dataset,\n",
    "    label_column_name=target_column_name,\n",
    "    compute_target=compute_target,\n",
    "    experiment_timeout_hours=1,\n",
    "    enable_early_stopping=True,\n",
    "    verbosity=logging.INFO,  # Set it to logging.ERROR for larger dataset\n",
    "    iterations=20,\n",
    "    max_concurrent_iterations=3,\n",
    "    enable_dnn=True,\n",
    "    allowed_models=[\"TCNForecaster\"],\n",
    "    use_distributed=True,\n",
    "    forecasting_parameters=forecasting_parameters,\n",
    "    max_nodes=6,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can now submit a new training run. Depending on the data and number of iterations this operation may take several minutes.\n",
    "Information from each iteration will be printed to the console.  Validation errors and current status will be shown when setting `show_output=True` and the execution will be synchronous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "remote_run = experiment.submit(automl_config, show_output=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_run.wait_for_completion(show_output=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "# If you need to retrieve a run that already started, use the following code\n",
    "# from azureml.train.automl.run import AutoMLRun\n",
    "# remote_run = AutoMLRun(experiment = experiment, run_id = '<replace with your run id>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "Displaying the run objects gives you links to the visual tools in the Azure Portal. Go try them!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "### Retrieve the Best Model for Each Algorithm\n",
    "Below we select the best pipeline from our iterations. The get_output method on automl_classifier returns the best run and the fitted model for the last fit invocation. There are overloads on get_output that allow you to retrieve the best run and fitted model for any logged metric or a particular iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "from helper import get_result_df\n",
    "\n",
    "\n",
    "summary_df = get_result_df(remote_run)\n",
    "summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "from azureml.core.run import Run\n",
    "from azureml.widgets import RunDetails\n",
    "\n",
    "forecast_model = \"TCNForecaster\"\n",
    "if not forecast_model in summary_df[\"run_id\"]:\n",
    "    forecast_model = \"ForecastTCN\"\n",
    "\n",
    "best_dnn_run_id = summary_df[summary_df[\"Score\"] == summary_df[\"Score\"].min()][\n",
    "    \"run_id\"\n",
    "][forecast_model]\n",
    "best_dnn_run = Run(experiment, best_dnn_run_id)\n",
    "model_name = best_dnn_run.properties[\"model_name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "best_dnn_run.parent\n",
    "RunDetails(best_dnn_run.parent).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "best_dnn_run\n",
    "RunDetails(best_dnn_run).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "## Evaluate on Test Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "We now use the best fitted model from the AutoML Run to make forecasts for the test set.  \n",
    "\n",
    "We always score on the original dataset whose schema matches the training set schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "# preview the first 5 rows of the dataset\n",
    "test_dataset.take(5).to_pandas_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_experiment = Experiment(ws, experiment_name + \"_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "\n",
    "script_folder = os.path.join(os.getcwd(), \"inference\")\n",
    "os.makedirs(script_folder, exist_ok=True)\n",
    "shutil.copy(\"infer.py\", script_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper import run_inference\n",
    "\n",
    "\n",
    "test_run = run_inference(\n",
    "    test_experiment,\n",
    "    compute_target,\n",
    "    script_folder,\n",
    "    best_dnn_run,\n",
    "    test_dataset,\n",
    "    valid_dataset,\n",
    "    forecast_horizon,\n",
    "    target_column_name,\n",
    "    time_column_name,\n",
    "    freq,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RunDetails(test_run).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Operationalize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Operationalization* means getting the model into the cloud so that other can run it after you close the notebook. We will create a docker running on Azure Container Instances with the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "description = \"AutoML UCI Electricity Forecaster\"\n",
    "tags = None\n",
    "model = remote_run.register_model(\n",
    "    model_name=model_name, description=description, tags=tags\n",
    ")\n",
    "\n",
    "print(remote_run.model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Develop the scoring script\n",
    "\n",
    "For the deployment we need a function which will run the forecast on serialized data. It can be obtained from the best_dnn_run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "script_file_name = \"score_forecaster.py\"\n",
    "best_dnn_run.download_file(\"outputs/scoring_file_v_1_0_0.py\", script_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy the model as a Web Service on Azure Container Instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.model import InferenceConfig\n",
    "from azureml.core.webservice import AciWebservice\n",
    "from azureml.core.webservice import Webservice\n",
    "from azureml.core.model import Model\n",
    "\n",
    "\n",
    "inference_config = InferenceConfig(\n",
    "    environment=best_dnn_run.get_environment(), entry_script=script_file_name\n",
    ")\n",
    "\n",
    "aciconfig = AciWebservice.deploy_configuration(\n",
    "    cpu_cores=2,\n",
    "    memory_gb=4,\n",
    "    tags={\"type\": \"automl-forecasting\"},\n",
    "    description=\"Automl forecasting sample service\",\n",
    ")\n",
    "\n",
    "aci_service_name = \"automl-uci-elec-forecast-01\"\n",
    "print(aci_service_name)\n",
    "aci_service = Model.deploy(ws, aci_service_name, [model], inference_config, aciconfig)\n",
    "aci_service.wait_for_deployment(True)\n",
    "print(aci_service.state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aci_service.get_logs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Call the service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "X_query = test_dataset.take(100).to_pandas_dataframe()\n",
    "X_query.pop(target_column_name)\n",
    "# We have to convert datetime to string, because Timestamps cannot be serialized to JSON.\n",
    "X_query[time_column_name] = X_query[time_column_name].astype(str)\n",
    "# The Service object accept the complex dictionary, which is internally converted to JSON string.\n",
    "# The section 'data' contains the data frame in the form of dictionary.\n",
    "test_sample = json.dumps({\"data\": X_query.to_dict(orient=\"records\")})\n",
    "response = aci_service.run(input_data=test_sample)\n",
    "\n",
    "try:\n",
    "    res_dict = json.loads(response)\n",
    "    y_fcst_all = pd.DataFrame(res_dict[\"index\"])\n",
    "    y_fcst_all[time_column_name] = pd.to_datetime(\n",
    "        y_fcst_all[time_column_name], unit=\"ms\"\n",
    "    )\n",
    "    y_fcst_all[\"forecast\"] = res_dict[\"forecast\"]\n",
    "except:\n",
    "    print(res_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_fcst_all.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete the web service if desired"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "serv = Webservice(ws, aci_service_name)\n",
    "serv.delete()  # don't do it accidentally"
   ]
  }
 ],
 "metadata": {
  "authors": [
   {
    "name": "jialiu"
   }
  ],
  "hide_code_all_hidden": false,
  "kernelspec": {
   "display_name": "Python 3.7.13 ('dev')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "6db9c8d9f0cce2d9127e384e15560d42c3b661994c9f717d0553d1d8985ab1ea"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
